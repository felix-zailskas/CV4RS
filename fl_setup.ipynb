{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\", header=None)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "df_c1, temp = train_test_split(df, test_size=0.7, random_state=seed)\n",
    "df_c2, df_c3 = train_test_split(df, test_size=0.5, random_state=seed)\n",
    "\n",
    "df_c1.to_csv(\"data/c1_train.csv\", index=False, header=None)\n",
    "df_c2.to_csv(\"data/c2_train.csv\", index=False, header=None)\n",
    "df_c3.to_csv(\"data/c3_train.csv\", index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_no = 1\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "epochs = 1\n",
    "\n",
    "channels = 10\n",
    "num_classes = 19\n",
    "dataset_filter = \"serbia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from utils.pytorch_datasets import Ben19Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FLCLient:\n",
    "    def __init__(self, model, lmdb_path, csv_path) -> None:\n",
    "        self.model = model\n",
    "        self.dataset = Ben19Dataset(lmdb_path, csv_path)\n",
    "        self.train_loader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        \n",
    "    def train_one_round(self):\n",
    "        state_before = self.model.state_dict()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, weight_decay=0)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            print(\"Epoch {}/{}\".format(epoch, epochs))\n",
    "            print(\"-\" * 10)\n",
    "\n",
    "            self.train_epoch(criterion, optimizer)\n",
    "        \n",
    "        state_after = self.model.state_dict()\n",
    "        \n",
    "        model_update = {}\n",
    "        for key, value_before in state_before.items():\n",
    "            value_after = state_after[key]\n",
    "            diff = value_after - value_before\n",
    "            model_update[key] = diff\n",
    "        \n",
    "        return model_update\n",
    "    \n",
    "    def train_epoch(self, criterion, optimizer):\n",
    "        self.model.train()\n",
    "        for idx, batch in enumerate(tqdm(self.train_loader, desc=\"training\")):\n",
    "            data, labels, index = batch[\"data\"], batch[\"label\"], batch[\"index\"]\n",
    "            data = data\n",
    "            labels = labels\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = self.model(data)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from utils.pytorch_utils import init_results, get_classification_report, update_results, print_micro_macro\n",
    "\n",
    "class GlobalClient:\n",
    "    def __init__(self, model, lmdb_path, csv_paths, val_path) -> None:\n",
    "        self.model = model\n",
    "        self.clients = [\n",
    "            FLCLient(copy.deepcopy(self.model), lmdb_path, csv_path) for csv_path in csv_paths\n",
    "        ]\n",
    "        self.validation_set = Ben19Dataset(\n",
    "            lmdb_path=lmdb_path, csv_path=val_path, img_transform=\"default\"\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            self.validation_set,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    \n",
    "    def train(self, communication_rounds):\n",
    "        results = init_results(num_classes)\n",
    "        \n",
    "        for com_round in range(1, communication_rounds + 1):\n",
    "            print(\"Round {}/{}\".format(com_round, communication_rounds))\n",
    "            print(\"-\" * 10)\n",
    "            \n",
    "            self.communication_round()\n",
    "            report = self.validation_round()\n",
    "            \n",
    "            results = update_results(results, report, num_classes)\n",
    "            print_micro_macro(report)\n",
    "            \n",
    "            for client in self.clients:\n",
    "                client.set_model(self.model)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def validation_round(self):\n",
    "        self.model.eval()\n",
    "        y_true = []\n",
    "        predicted_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(tqdm(self.val_loader, desc=\"test\")):\n",
    "                data = batch[\"data\"]\n",
    "                labels = batch[\"label\"].numpy()\n",
    "\n",
    "                logits = self.model(data)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "                predicted_probs += list(probs)\n",
    "\n",
    "                y_true += list(labels)\n",
    "\n",
    "        predicted_probs = np.asarray(predicted_probs)\n",
    "        y_predicted = (predicted_probs >= 0.5).astype(np.float32)\n",
    "\n",
    "        y_true = np.asarray(y_true)\n",
    "        report = get_classification_report(\n",
    "            y_true, y_predicted, predicted_probs, dataset_filter\n",
    "        )\n",
    "        return report\n",
    "    \n",
    "    def communication_round(self):\n",
    "        # here the clients train\n",
    "        # TODO: could be parallelized\n",
    "        model_updates = [client.train_one_round() for client in self.clients]\n",
    "        \n",
    "        # parameter aggregation\n",
    "        update_aggregation = {}\n",
    "        for key in model_updates[0].keys():\n",
    "            params = torch.stack([update[key] for update in model_updates], dim=0)\n",
    "            avg = torch.mean(params, dim=0)\n",
    "            update_aggregation[key] = avg\n",
    "        \n",
    "        # update the global model\n",
    "        self.model.load_state_dict(update_aggregation)\n",
    "        # self.model.load_state_dict(model_updates[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cv4rs/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cv4rs/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/1\n",
      "----------\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/19 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/31 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/31 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m ResNet18(num_cls\u001b[39m=\u001b[39mnum_classes, channels\u001b[39m=\u001b[39mchannels, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m global_client \u001b[39m=\u001b[39m GlobalClient(model, \u001b[39m\"\u001b[39m\u001b[39mdata/BigEarth_Serbia_Summer_S2.lmdb\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mdata/c1_train.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata/c2_train.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata/c3_train.csv\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mdata/test.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m results \u001b[39m=\u001b[39m global_client\u001b[39m.\u001b[39mtrain(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRound \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(com_round, communication_rounds))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommunication_round()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m report \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_round()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m results \u001b[39m=\u001b[39m update_results(results, report, num_classes)\n",
      "\u001b[1;32m/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m model_updates[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([update[key] \u001b[39mfor\u001b[39;00m update \u001b[39min\u001b[39;00m model_updates], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     avg \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(params, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     update_aggregation[key] \u001b[39m=\u001b[39m avg\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felixzailskas/Code/CV4RS/fl_setup.ipynb#W5sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# update the global model\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "from utils.pytorch_models import ResNet18\n",
    "\n",
    "model = ResNet18(num_cls=num_classes, channels=channels, pretrained=True)\n",
    "\n",
    "global_client = GlobalClient(model, \"data/BigEarth_Serbia_Summer_S2.lmdb\", [\"data/c1_train.csv\", \"data/c2_train.csv\", \"data/c3_train.csv\"], \"data/test.csv\")\n",
    "results = global_client.train(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
