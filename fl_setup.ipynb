{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the dataset. This only needs to be done once. We use a seed to ensure consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from utils.pytorch_models import ResNet18\n",
    "from models.poolformer import create_poolformer_s12\n",
    "from models.ConvMixer import create_convmixer_1024_20\n",
    "from models.MLPMixer import create_mlp_mixer\n",
    "from utils.clients import GlobalClient\n",
    "from utils.pytorch_utils import start_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_path = Path(\"data/c1_train.csv\")\n",
    "c2_path = Path(\"data/c2_train.csv\")\n",
    "c3_path = Path(\"data/c3_train.csv\")\n",
    "if not (c1_path.exists() and c2_path.exists() and c3_path.exists()):\n",
    "    df = pd.read_csv(\"data/train.csv\", header=None)\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    df_c1, temp = train_test_split(df, test_size=(2/3), random_state=seed)\n",
    "    df_c2, df_c3 = train_test_split(temp, test_size=0.5, random_state=seed)\n",
    "\n",
    "    df_c1.to_csv(\"data/c1_train.csv\", index=False, header=None)\n",
    "    df_c2.to_csv(\"data/c2_train.csv\", index=False, header=None)\n",
    "    df_c3.to_csv(\"data/c3_train.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_no = 1\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "epochs = 10\n",
    "communication_rounds = 20\n",
    "\n",
    "channels = 10\n",
    "num_classes = 19\n",
    "dataset_filter = \"serbia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ConvMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convmixer = create_convmixer_1024_20(channels, num_classes)\n",
    "global_client_convmixer = GlobalClient(\n",
    "    model=convmixer,\n",
    "    lmdb_path=\"data/BigEarth_Serbia_Summer_S2.lmdb\",\n",
    "    val_path=\"data/test.csv\",\n",
    "    csv_paths=[\"data/c1_train.csv\", \"data/c2_train.csv\", \"data/c3_train.csv\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/20\n",
      "----------\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "global_convmixer_results, global_convmixer_client_results = global_client_convmixer.train(communication_rounds=communication_rounds, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train PoolFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolformer_s12 = create_poolformer_s12(in_chans=channels, num_classes=num_classes)\n",
    "global_client_poolformer = GlobalClient(\n",
    "    model=poolformer_s12,\n",
    "    lmdb_path=\"data/BigEarth_Serbia_Summer_S2.lmdb\",\n",
    "    val_path=\"data/test.csv\",\n",
    "    csv_paths=[\"data/c1_train.csv\", \"data/c2_train.csv\", \"data/c3_train.csv\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_poolformer_results, global_poolformer_client_results = global_client_poolformer.train(communication_rounds=communication_rounds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet18(num_cls=num_classes, channels=channels, pretrained=True)\n",
    "global_client_resnet18 = GlobalClient(\n",
    "    model=resnet18,\n",
    "    lmdb_path=\"data/BigEarth_Serbia_Summer_S2.lmdb\",\n",
    "    val_path=\"data/test.csv\",\n",
    "    csv_paths=[\"data/c1_train.csv\", \"data/c2_train.csv\", \"data/c3_train.csv\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_resnet18_results, global_resnet18_client_results = global_client_resnet18.train(communication_rounds=communication_rounds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP-Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mixer = create_mlp_mixer(channels, num_classes)\n",
    "global_client_mlp_mixer = GlobalClient(\n",
    "    model=mlp_mixer,\n",
    "    lmdb_path=\"data/BigEarth_Serbia_Summer_S2.lmdb\",\n",
    "    val_path=\"data/test.csv\",\n",
    "    csv_paths=[\"data/c1_train.csv\", \"data/c2_train.csv\", \"data/c3_train.csv\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mlp_mixer_results, global_mlp_mixer_client_results = global_client_mlp_mixer.train(communication_rounds=communication_rounds, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
